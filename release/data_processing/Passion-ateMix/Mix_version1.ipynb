{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7645bcac-9daf-4925-9250-1b24b35f5447",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9469ab4-f8c2-401b-b1f3-2eb16d81f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e002b-9bed-4a30-9198-3c0a787089b3",
   "metadata": {},
   "source": [
    "## Read Annotations files & DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d401d4-dd5f-443b-9821-c04cd72907d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path  = './segmentation/input/data/'\n",
    "df = pd.read_csv('./segmentation/baseline_code/class_dict.csv')\n",
    "\n",
    "category_names = list(df.name)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30ea83-5b8a-48eb-a5ae-2010203de3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 증강시킬 json 파일을 train_path에 넣어주세요\n",
    "json_path = dataset_path + '/train_all.json'\n",
    "\n",
    "coco = COCO(json_path)\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef73fa-d39c-4247-894b-e35b25b20ff0",
   "metadata": {},
   "source": [
    "## Define Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839a6d7-bd8c-4684-b108-a646d80c295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강시키고자 하는 mask_class 선언\n",
    "# ex) battery를 증강하려면 9 입력\n",
    "\n",
    "mask_class = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aaa128-bea2-4310-bd31-9809b6e3479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 mask_class가 들어있는 images의 인덱스들\n",
    "foreground_images = []\n",
    "\n",
    "for idx in tqdm(range(len(json_data['images']))):\n",
    "    image_id = coco.getImgIds(imgIds=idx)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "    \n",
    "    ann_ids = coco.getAnnIds(imgIds=image_infos['id'])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "    \n",
    "    category_type = []\n",
    "    for i in range(len(anns)):\n",
    "        category_id = anns[i]['category_id']\n",
    "        if category_id == mask_class:\n",
    "            foreground_images.append(idx)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5b82e-8dd3-4475-b170-d83467bf3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json data 파일의 마지막 images id 추출\n",
    "last_images_id = json_data['images'][-1]['id']\n",
    "\n",
    "# mask_class가 없는 이미지에 증강시킬 목적으로 \n",
    "# mask_class가 없는 이미지들의 인덱스 background_images 선언\n",
    "background_images = range(last_images_id)\n",
    "background_images = [x for x in background_images if x not in foreground_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079ba9c-0270-42c6-8532-2e2162341e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강시킬 개수 k\n",
    "\n",
    "k = 19\n",
    "fg_image_idx = random.sample(foreground_images, k)\n",
    "bg_image_idx = random.sample(background_images, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7219275f-2503-4995-858b-dc9c7e132558",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e11f0-cc14-4797-8b05-34f425c4b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fg_idx, bg_idx in zip(fg_image_idx, bg_image_idx):\n",
    "    ## 원본으로 쓰일 이미지\n",
    "    ## 여기서는 원본 이미지에서 배경에 해당하는 공간을 찾을 것임\n",
    "\n",
    "    ## idx에 해당하는 이미지 정보 추출\n",
    "    idx = bg_idx\n",
    "\n",
    "    image_id = coco.getImgIds(imgIds=idx)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=image_infos['id'])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    cat_ids = coco.getCatIds()\n",
    "    cats = coco.loadCats(cat_ids)\n",
    "\n",
    "    masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "\n",
    "    anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "    for i in range(len(anns)):\n",
    "        className = get_classname(anns[i]['category_id'], cats)\n",
    "        pixel_value = category_names.index(className)\n",
    "        masks[coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "\n",
    "    masks = masks.astype(np.int8)\n",
    "\n",
    "    # 해당 이미지 시각화\n",
    "    images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "    images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # temp_images에다가 합성할 예정\n",
    "    temp_infos = copy.deepcopy(image_infos)\n",
    "    temp_images = copy.deepcopy(images)\n",
    "\n",
    "    # background에서 빈 공간을 찾기 위해\n",
    "    # background_mask 선언\n",
    "    background_mask = (masks == 0)\n",
    "\n",
    "\n",
    "    # 공간 찾는 로직\n",
    "    edge = 0\n",
    "    graph = [[x for x in sub] for sub in background_mask]\n",
    "\n",
    "    for x in range(1, len(graph)):\n",
    "        for y in range(1, len(graph)):\n",
    "            if graph[x][y] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                _min = min([graph[x][y-1], graph[x-1][y], graph[x-1][y-1]])\n",
    "                graph[x][y] = _min + 1\n",
    "                if edge < graph[x][y]:\n",
    "                    edge = graph[x][y]\n",
    "\n",
    "    flag = False\n",
    "\n",
    "    for x in range(1, len(graph)):\n",
    "        if flag: \n",
    "            break\n",
    "        for y in range(1, len(graph)):\n",
    "            if graph[x][y] == edge:\n",
    "                empty_ymax, empty_xmax = x+1, y+1\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "    # 찾은 빈공간 확인\n",
    "    # plt.imshow(images[empty_ymax-edge:empty_ymax, empty_xmax-edge:empty_xmax])\n",
    "\n",
    "    ## 추출하려는 이미지\n",
    "    ## 여기서는 원하는 mask_class에 따라 물체를 추출할 것임\n",
    "\n",
    "    ## idx에 해당하는 이미지 정보 추출\n",
    "    idx = fg_idx\n",
    "\n",
    "    image_id = coco.getImgIds(imgIds=idx)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=image_infos['id'])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    cat_ids = coco.getCatIds()\n",
    "    cats = coco.loadCats(cat_ids)\n",
    "\n",
    "    masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "\n",
    "    anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "    for i in range(len(anns)):\n",
    "        className = get_classname(anns[i]['category_id'], cats)\n",
    "        pixel_value = category_names.index(className)\n",
    "        masks[coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "\n",
    "    masks = masks.astype(np.int8)\n",
    "\n",
    "    # 해당 이미지 시각화\n",
    "\n",
    "    images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "    images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(images)\n",
    "\n",
    "    masks = (masks == mask_class).astype(np.int8)\n",
    "\n",
    "    # masking된 모든 물체 src\n",
    "    # src를 뺀 background 선언\n",
    "\n",
    "    src = cv2.bitwise_and(images, images, mask=masks)\n",
    "    background = cv2.bitwise_not(images, images, mask=masks)\n",
    "\n",
    "    ## 해당 물체의 bbox 찾는 로직\n",
    "    ## class당 annotation이 여러개일 수 있기 때문에 for문을 통해 bbox 탐지\n",
    "\n",
    "    ymin, ymax = 0, 0\n",
    "\n",
    "    for y in range(len(src)):\n",
    "        if (masks[y].sum() != 0) and ymin == 0:\n",
    "            ymin = y\n",
    "        elif masks[y].sum() != 0:\n",
    "            ymax = y        \n",
    "\n",
    "    xmin, xmax = 0, 0\n",
    "\n",
    "    for x in range(len(src[0])):\n",
    "        if (masks[:, x].sum() != 0) and xmin == 0:\n",
    "            xmin = x\n",
    "        elif masks[:, x].sum() != 0:\n",
    "            xmax = x\n",
    "\n",
    "\n",
    "    ## segmenatation값 처리\n",
    "\n",
    "    segmentation_roi = masks[ymin:ymax, xmin:xmax]\n",
    "    resized_segmentation_roi = cv2.resize(segmentation_roi.astype(np.uint8), dsize=(edge, edge), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    segmentation_mask = np.zeros((512, 512))\n",
    "    segmentation_mask[empty_ymax-edge:empty_ymax, empty_xmax-edge:empty_xmax] = resized_segmentation_roi\n",
    "\n",
    "    # mask 물체 추출\n",
    "    extract_mask = src[ymin:ymax, xmin:xmax]\n",
    "\n",
    "\n",
    "    # 빈공간 size에 맞게 resize\n",
    "    if edge * edge > (ymax-ymin) * (xmax-xmin):\n",
    "        resized_src = cv2.resize(extract_mask, dsize=(edge, edge), interpolation=cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized_src = cv2.resize(extract_mask, dsize=(edge, edge), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # 원본 이미지에서 관심영역(roi) 설정\n",
    "    # roi는 원본 이미지에서 찾은 빈 공간\n",
    "    roi = temp_images[empty_ymax-edge:empty_ymax, empty_xmax-edge:empty_xmax]\n",
    "\n",
    "    # 이미지 합성을 위해 bg_mask, fg_mask 생성\n",
    "    resized_src_gray = cv2.cvtColor(resized_src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    bg_mask = (resized_src_gray == 0).astype(np.int8)\n",
    "    fg_mask = (resized_src_gray != 0).astype(np.int8)\n",
    "\n",
    "    # roi에서 뜯어 붙일 이미지 공간을 제외한 배경 추출\n",
    "    # resized_src에서 뜯어 붙일 이미지 추출\n",
    "    bg = cv2.bitwise_and(roi, roi, mask=bg_mask)\n",
    "    fg = cv2.bitwise_and(resized_src, resized_src, mask=fg_mask)\n",
    "\n",
    "    # 이미지 합성\n",
    "    merged_image = cv2.bitwise_or(bg, fg)\n",
    "\n",
    "    # 원본 이미지에 합성한 이미지 붙이기\n",
    "    temp_images[empty_ymax-edge:empty_ymax, empty_xmax-edge:empty_xmax] = merged_image\n",
    "\n",
    "\n",
    "    ## 증강된 이미지 저장\n",
    "\n",
    "    saved_dir = '/opt/ml/segmentation/input/data/augmented/'\n",
    "    file_name_dir = 'augmented/'\n",
    "    if not os.path.isdir(saved_dir):                                                           \n",
    "        os.mkdir(saved_dir)\n",
    "\n",
    "    temp_images = cv2.cvtColor(temp_images, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(saved_dir + temp_infos['file_name'].split('/')[-1], temp_images)\n",
    "\n",
    "\n",
    "    # 수정해야할 image_id\n",
    "    revised_id = temp_infos['id']\n",
    "\n",
    "    # json으로 읽어들일 image 수정\n",
    "    json_data['images'][revised_id]['file_name'] = file_name_dir + temp_infos['file_name'].split('/')[-1]\n",
    "\n",
    "\n",
    "    fortran_ground_truth_binary_mask = np.asfortranarray(segmentation_mask).astype(np.uint8)\n",
    "    encoded_ground_truth = mask.encode(fortran_ground_truth_binary_mask)\n",
    "    ground_truth_area = mask.area(encoded_ground_truth)\n",
    "    ground_truth_bounding_box = mask.toBbox(encoded_ground_truth)\n",
    "    contours, hierarchy = cv2.findContours(segmentation_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    annotation = {\n",
    "            \"segmentation\": [],\n",
    "            \"area\": ground_truth_area.tolist(),\n",
    "            \"iscrowd\": 0,\n",
    "            \"image_id\": temp_infos['id'],\n",
    "            \"bbox\": ground_truth_bounding_box.tolist(),\n",
    "            \"category_id\": mask_class,\n",
    "            \"id\": json_data['annotations'][-1]['id'] + 1\n",
    "        }\n",
    "\n",
    "\n",
    "    for contour in contours:\n",
    "        contour = np.flip(contour, axis=1)\n",
    "        segmentation = contour.ravel().tolist()\n",
    "        annotation['segmentation'].append(segmentation)\n",
    "\n",
    "\n",
    "    json_data['annotations'].append(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ac7b0-415e-4d40-b6a0-446c029bc420",
   "metadata": {},
   "source": [
    "## Save New Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22cdc0-7fb1-4ddb-8745-384c6c8f3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강이 끝나면 json file 저장\n",
    "\n",
    "with open(dataset_path + 'mix_json.json', 'w') as outfile:\n",
    "    json.dump(json_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
