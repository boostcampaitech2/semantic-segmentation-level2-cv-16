{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.7.1+cu110\n",
      "GPU 사용 가능 여부: True\n",
      "Tesla V100-SXM2-32GB\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from models.UNet_3Plus import UNet_3Plus_DeepSup_CGM, UNet_3Plus_DeepSup\n",
    "from loss.bceLoss import BCE_loss\n",
    "from loss.iouLoss import IOU,IOU_loss\n",
    "from loss.msssimLoss import MSSSIM\n",
    "\n",
    "from dataloader.cocoform_loader import CustomDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_json_path = \"/opt/ml/segmentation/input/data/\"\n",
    "train_json_path = common_json_path + \"train.json\"\n",
    "val_json_path = common_json_path + \"val.json\"\n",
    "test_json_path = common_json_path + \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.78s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=1.24s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(\n",
    "    common_dir=common_json_path, json_path=train_json_path, \n",
    "    mode='train', transform=train_transform\n",
    ")\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(\n",
    "    common_dir=common_json_path, json_path=val_json_path, \n",
    "    mode='val', transform=val_transform\n",
    ")\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(\n",
    "    common_dir=common_json_path, json_path=test_json_path, \n",
    "    mode='test', transform=test_transform\n",
    ")\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    # num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet_3Plus_DeepSup, UNet_3Plus_DeepSup_CGM\n",
    "model = UNet_3Plus_DeepSup_CGM(\n",
    "    in_channels=3,\n",
    "    n_classes=len(train_dataset.category_names),\n",
    "    # feature_scale=4,\n",
    "    is_deconv=True,\n",
    "    is_batchnorm=True\n",
    ")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_batch = next(iter(train_loader))\n",
    "x, y, cls_label = list(map(torch.stack, a_batch))\n",
    "cls_branch, Dec = model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss().cuda()\n",
    "bce_out = bce_loss(cls_branch, cls_label.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_loss = IOU(size_average=True)\n",
    "for D in Dec:\n",
    "    iou_out = iou_loss(D, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_ssim = MSSSIM()\n",
    "for D in Dec:\n",
    "    msssim_out = ms_ssim(D, y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b11598256ab570a6f12738363c4bc02be2fcd90c8b0e5072a705df3558da51b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('UNet3p': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
