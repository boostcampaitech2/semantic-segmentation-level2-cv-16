{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e16e283-c13c-4085-97dd-1abf59a06a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score, add_hist\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ttach as tta\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "##내가 사용할 모델정보 py파일 import해야된다 + 데이터로더도 같이\n",
    "from smp_unet import *\n",
    "from dataloader import *\n",
    "# GPU 사용 가능 여부에 따라 device 정보 저장\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce3d370-89c2-4939-9221-329410e8fdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "test_path = \"/opt/ml/segmentation/input/data/test.json\"\n",
    "\n",
    "test_transform = A.Compose([\n",
    "#                             A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.2, p=0.5),\n",
    "                           ToTensorV2() \n",
    "])\n",
    "\n",
    "\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=8,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17032757-2f08-470f-9da0-7cb0a2912def",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './test/pseudo_2/best.pth'\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model = myModel(\"UnetPlusPlus\",\"timm-efficientnet-b4\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef739f9-db4e-407e-ab31-7f0f0bd7a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_transform = tta.Compose([\n",
    "    tta.HorizontalFlip(),\n",
    "    tta.VerticalFlip(),\n",
    "    tta.Rotate90([0,90])\n",
    "])\n",
    "tta_model = tta.SegmentationTTAWrapper(model, tta_transform, merge_mode = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86941ba5-6c5d-4c18-95b9-fd041d1931a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    #### 슈도할때는 512\n",
    "    #### 그냥 라벨링 할때는 256\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(size, size)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(tqdm(test_loader)):\n",
    "            \n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "                \n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ef3f323-574d-43ac-b91a-50bda55c272b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [08:13<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n"
     ]
    }
   ],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(tta_model, test_loader, device)\n",
    "\n",
    "##### image name을 npy로 저장\n",
    "#### 슈도 라벨링할때만 사용\n",
    "'''\n",
    "name_list = []\n",
    "for i in file_names:\n",
    "    name_list.append(i)\n",
    "np.save('/opt/ml/segmentation/input/data/img_name', name_list)\n",
    "'''\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission11_deeplab.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23e6a1-d8e6-40b6-91b4-e808f43a742f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### 재현님 코드 참고했습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468c86e3-eaf5-4b43-b36c-623ec100c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/opt/ml/segmentation/unet3/submission10_deeplab.csv')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    cur = df.iloc[i, :]\n",
    "    arr = np.array(cur['PredictionString'].split()).reshape(512, 512)\n",
    "    np.save('/opt/ml/segmentation/input/data/mask3_deeplab/' + format(i, '03') , arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "395d8b59-557d-4ad4-8549-efa82bb2ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512 512\n"
     ]
    }
   ],
   "source": [
    "print(len(arr[0]),len(arr[220]),len(arr[511]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "segmentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
